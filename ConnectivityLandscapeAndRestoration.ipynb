{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467b6f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the layers, variables and parameters\n",
    "\n",
    "import os\n",
    "import math\n",
    "import arcpy\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from arcpy import env\n",
    "env.parallelProcessingFactor = \"100%\"  # use all available cores\n",
    "env.overwriteOutput = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abc6653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Layers\n",
    "\n",
    "dir = r\"C:\\Capstone\\ConnectivityAnalyses\"\n",
    "study_area = os.path.join(dir,\"ShelbyROI.shp\")\n",
    "hexagons = os.path.join(dir,\"hexagons.shp\")\n",
    "patches_layer = os.path.join(dir,\"patchROI.shp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6fdb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting coordinate system\n",
    "\n",
    "# Define target projected coordinate system\n",
    "projected_crs = arcpy.SpatialReference(26916)  # NAD 1983 UTM Zone 16N (meters)\n",
    "\n",
    "# Create a folder for projected data\n",
    "projected_dir = os.path.join(dir, \"Projected\")\n",
    "os.makedirs(projected_dir, exist_ok=True)\n",
    "\n",
    "# Define projected file paths\n",
    "study_area_proj = os.path.join(projected_dir, \"ShelbyROI_UTM16N.shp\")\n",
    "patches_layer_proj = os.path.join(projected_dir, \"patchROI_UTM16N.shp\")\n",
    "hexagons_proj = os.path.join(projected_dir, \"hexagons_UTM16N.shp\")\n",
    "\n",
    "# Project original layers into UTM Zone 16N (meters)\n",
    "arcpy.management.Project(study_area, study_area_proj, projected_crs)\n",
    "arcpy.management.Project(patches_layer, patches_layer_proj, projected_crs)\n",
    "arcpy.management.Project(hexagons, hexagons_proj, projected_crs)\n",
    "\n",
    "study_area = study_area_proj\n",
    "patches_layer = patches_layer_proj\n",
    "hexagons = hexagons_proj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "970ce1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting variables\n",
    "\n",
    "# Set the variable for the hexagons area field\n",
    "area_hexagons = \"Area_m2\"\n",
    "area_patches = \"Area_m2\"\n",
    "\n",
    "# Set the variable for the hexagons ID field\n",
    "ID_field = \"GRID_ID\"\n",
    "\n",
    "# Set the variable for the name of the pc index shapefile\n",
    "hexagons_pc = f\"{hexagons[:-4]}_pc.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "506fe5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "\n",
    "distance = 500 # Distance threshold\n",
    "pij = 0.5 # Probability of dispersal\n",
    "radius = distance*4\n",
    "area_hex = 3*math.sqrt(3)/2*radius**2 # Area calculated using radius 3 times the mean dispersal distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc0f236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, November 5, 2025 10:34:37 AM\",\"Succeeded at Wednesday, November 5, 2025 10:34:37 AM (Elapsed Time: 0.34 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Capstone\\\\ConnectivityAnalyses\\\\Projected\\\\hexagons_UTM16N.shp'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the hexagons grid shapefile\n",
    "\n",
    "hexagons_temp = os.path.join(dir,\"hexagons_temp.shp\") \n",
    "\n",
    "arcpy.ba.GenerateGridsAndHexagons(\n",
    "    area_of_interest=study_area,\n",
    "    out_feature_class=hexagons_temp, # Uses the full path defined above\n",
    "    cell_type=\"HEXAGON\",\n",
    "    enrich_type=\"\",\n",
    "    cell_size=f\"{area_hex} SquareMeters\",\n",
    "    h3_resolution=7,\n",
    "    variables=None,\n",
    "    distance_type=\"STRAIGHT_LINE_DISTANCE\",\n",
    "    distance=1,\n",
    "    units=\"MILES\",\n",
    "    out_enriched_buffers=None,\n",
    "    travel_direction=\"TOWARD_STORES\",\n",
    "    time_of_day=None,\n",
    "    time_zone=\"TIME_ZONE_AT_LOCATION\",\n",
    "    search_tolerance=None,\n",
    "    polygon_detail=\"STANDARD\",\n",
    "    out_centroids=None\n",
    ")\n",
    "\n",
    "# Select hexagons that intersect (touch or fall within) the study area\n",
    "arcpy.management.MakeFeatureLayer(hexagons_temp, \"hex_layer\")\n",
    "arcpy.management.SelectLayerByLocation(\n",
    "    in_layer=\"hex_layer\",\n",
    "    overlap_type=\"INTERSECT\",  # keeps any hexagon that touches or overlaps\n",
    "    select_features=study_area,\n",
    "    selection_type=\"NEW_SELECTION\"\n",
    ")\n",
    "\n",
    "# Export the selected hexagons (unclipped) to 'hexagons'\n",
    "arcpy.management.CopyFeatures(\"hex_layer\", hexagons)\n",
    "\n",
    "# Define spatial reference\n",
    "desc_study_area = arcpy.Describe(study_area)\n",
    "spatial_reference = desc_study_area.spatialReference\n",
    "\n",
    "# Define type for area_hexagons attribute field\n",
    "arcpy.AddField_management(hexagons, area_hexagons, \"DOUBLE\")\n",
    "\n",
    "# Calculate the area of the hexagons\n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "    in_features=hexagons,\n",
    "    geometry_property=\"Area_m2 AREA\",\n",
    "    length_unit=\"\",\n",
    "    area_unit=\"SQUARE_METERS\",\n",
    "    coordinate_system=spatial_reference,\n",
    "    coordinate_format=\"SAME_AS_INPUT\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b45f171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to calculate the probability of connectivity index (PC index) for a given set of patches\n",
    "# and a given distance threshold, following Saura & Pascual-Hortal (2007).\n",
    "\n",
    "def PC_index(patches, area_field, total_area, distance, pij):\n",
    "    \"\"\"\n",
    "    Function to calculate the probability of connectivity index (PC index) for a given set of patches,\n",
    "    following Saura & Pascual-Hortal (2007).\n",
    "    Parameters:\n",
    "    - patches(str):\n",
    "        Path to the patches shapefile\n",
    "    - area_field(str):\n",
    "        Name of the field containing the area of the patches\n",
    "    - total_area(float):\n",
    "        Area of the study area\n",
    "    - distance(float):\n",
    "        Distance threshold (in meters)\n",
    "    - pij(float):\n",
    "        Probability of dispersal at the median distance\n",
    "    Returns:\n",
    "    - pc_index_global(float):\n",
    "        Probability of connectivity index (PC index) for the given set of patches\n",
    "    \"\"\"\n",
    "    import arcpy\n",
    "    import math\n",
    "\n",
    "    # decay constant k\n",
    "    k = -math.log(pij) / distance\n",
    "\n",
    "    # calculate areas for patches (if not already present)\n",
    "    arcpy.management.CalculateGeometryAttributes(\n",
    "        in_features=patches,\n",
    "        geometry_property=f\"{area_field} AREA\",\n",
    "        area_unit=\"SQUARE_METERS\"\n",
    "    )\n",
    "\n",
    "    # collect patch areas\n",
    "    patch_areas = {}\n",
    "    with arcpy.da.SearchCursor(patches, [\"OID@\", area_field]) as cur:\n",
    "        for oid, area in cur:\n",
    "            patch_areas[oid] = area\n",
    "\n",
    "    # generate near table (pairwise distances)\n",
    "    near_table = f\"{patches[:-4]}_near.dbf\"\n",
    "    arcpy.analysis.GenerateNearTable(\n",
    "        in_features=patches,\n",
    "        near_features=patches,\n",
    "        out_table=near_table,\n",
    "        location=\"NO_LOCATION\",\n",
    "        angle=\"NO_ANGLE\",\n",
    "        closest=\"ALL\",\n",
    "        method=\"PLANAR\",\n",
    "        distance_unit=\"Meters\"\n",
    "    )\n",
    "\n",
    "    # add self-links (distance = 0)\n",
    "    with arcpy.da.SearchCursor(patches, [\"OID@\"]) as s:\n",
    "        with arcpy.da.InsertCursor(near_table, [\"IN_FID\", \"NEAR_FID\", \"NEAR_DIST\"]) as ins:\n",
    "            for (oid,) in s:\n",
    "                ins.insertRow((oid, oid, 0.0))\n",
    "\n",
    "    # compute numerator: ΣΣ a_i * a_j * exp(-k * d_ij)\n",
    "    numerator = 0.0\n",
    "    with arcpy.da.SearchCursor(near_table, [\"IN_FID\", \"NEAR_FID\", \"NEAR_DIST\"]) as cur:\n",
    "        for i, j, dist in cur:\n",
    "            numerator += patch_areas[i] * patch_areas[j] * math.exp(-k * dist)\n",
    "\n",
    "    # final PC\n",
    "    pc_global = numerator / (total_area ** 2)\n",
    "    return pc_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7a89b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hexagon C-15 has no patches. Setting PC to 0.\n",
      "Hexagon E-15 has no patches. Setting PC to 0.\n",
      "Hexagon G-15 has no patches. Setting PC to 0.\n",
      "Hexagon I-15 has no patches. Setting PC to 0.\n",
      "Hexagon K-15 has no patches. Setting PC to 0.\n",
      "Hexagon A-13 has no patches. Setting PC to 0.\n",
      "Hexagon D-13 has no patches. Setting PC to 0.\n",
      "Hexagon C-12 has no patches. Setting PC to 0.\n",
      "Hexagon L-11 has no patches. Setting PC to 0.\n",
      "Hexagon E-10 has no patches. Setting PC to 0.\n",
      "Hexagon F-10 has no patches. Setting PC to 0.\n",
      "Hexagon J-10 has no patches. Setting PC to 0.\n",
      "Hexagon M-10 has no patches. Setting PC to 0.\n",
      "Hexagon G-9 has no patches. Setting PC to 0.\n",
      "Hexagon W-8 has no patches. Setting PC to 0.\n",
      "Hexagon F-7 has no patches. Setting PC to 0.\n",
      "Hexagon W-7 has no patches. Setting PC to 0.\n",
      "Hexagon W-6 has no patches. Setting PC to 0.\n",
      "Hexagon E-5 has no patches. Setting PC to 0.\n",
      "Hexagon W-5 has no patches. Setting PC to 0.\n",
      "Hexagon G-4 has no patches. Setting PC to 0.\n",
      "Hexagon W-4 has no patches. Setting PC to 0.\n",
      "Hexagon G-3 has no patches. Setting PC to 0.\n",
      "Hexagon W-3 has no patches. Setting PC to 0.\n",
      "Hexagon V-2 has no patches. Setting PC to 0.\n",
      "Hexagon W-2 has no patches. Setting PC to 0.\n",
      "Hexagon I-1 has no patches. Setting PC to 0.\n",
      "Hexagon J-1 has no patches. Setting PC to 0.\n",
      "Hexagon K-1 has no patches. Setting PC to 0.\n",
      "Hexagon M-1 has no patches. Setting PC to 0.\n",
      "Hexagon S-1 has no patches. Setting PC to 0.\n"
     ]
    }
   ],
   "source": [
    "#Step 1. Calculate the pc index for each hexagon using the patches shapefile\n",
    "\n",
    "# Copy the hexagons shapefile to a new shapefile\n",
    "arcpy.management.CopyFeatures(hexagons, hexagons_pc)\n",
    "\n",
    "# Add the fields to the new shapefile\n",
    "arcpy.AddField_management(hexagons_pc, \"PC\", \"DOUBLE\")\n",
    "arcpy.AddField_management(hexagons_pc, \"ratio\", \"DOUBLE\")\n",
    "arcpy.AddField_management(hexagons_pc, \"Threshold\", \"TEXT\")\n",
    "\n",
    "# Create a new folder to store the patches for each hexagon\n",
    "dir_patches = os.path.join(dir, \"PatchesHex\")\n",
    "os.makedirs(dir_patches, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "\n",
    "with arcpy.da.UpdateCursor(hexagons_pc, [ID_field, area_hexagons, \"PC\", \"ratio\",\"Threshold\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        grid_id, area, pc_value, ratio_area, threshold = row\n",
    "        where_clause = f\"{ID_field} = '{grid_id}'\"\n",
    "        target_hex = arcpy.SelectLayerByAttribute_management(hexagons, \"NEW_SELECTION\", where_clause)\n",
    "        patches_hex = os.path.join(dir_patches, f\"{grid_id}.shp\")\n",
    "\n",
    "        # Clip patches to the current hexagon\n",
    "        arcpy.analysis.PairwiseClip(patches_layer, target_hex, patches_hex)\n",
    "\n",
    "        # Check if there are patches in this hexagon\n",
    "        count_result = arcpy.management.GetCount(patches_hex)\n",
    "        count = int(count_result.getOutput(0))\n",
    "\n",
    "        if count == 0:\n",
    "            pc_value = 0\n",
    "            ratio_area = 0\n",
    "            threshold = \"Low\"\n",
    "            print(f\"Hexagon {grid_id} has no patches. Setting PC to 0.\")\n",
    "        else:\n",
    "            # Ensure Area_m2 field exists\n",
    "            fields = [f.name for f in arcpy.ListFields(patches_hex)]\n",
    "            if area_patches not in fields:\n",
    "                arcpy.AddField_management(patches_hex, area_patches, \"DOUBLE\")\n",
    "\n",
    "            # Calculate the area for the patches in this hexagon\n",
    "            desc_patches = arcpy.Describe(patches_hex)\n",
    "            sr_patches = desc_patches.spatialReference\n",
    "\n",
    "            arcpy.management.CalculateGeometryAttributes(\n",
    "                in_features=patches_hex,\n",
    "                geometry_property=[[area_patches, \"AREA\"]],\n",
    "                area_unit=\"SQUARE_METERS\",\n",
    "                coordinate_system=sr_patches\n",
    "            )\n",
    "\n",
    "            # Compute PC for the hexagon\n",
    "            pc_value = PC_index(\n",
    "                patches=patches_hex,\n",
    "                area_field=area_patches,\n",
    "                total_area=area,\n",
    "                distance=distance,\n",
    "                pij=pij\n",
    "            )\n",
    "\n",
    "            # Calculate the patches_area/hexagon_area ratio\n",
    "            with arcpy.da.SearchCursor(patches_hex, [area_patches]) as patches_cursor:\n",
    "                patches_area = sum(row[0] for row in patches_cursor)\n",
    "            ratio_area = patches_area / area\n",
    "\n",
    "            # Classify based on ratio\n",
    "            if ratio_area > 0.6:\n",
    "                threshold = \"Biodiversity source\"\n",
    "            elif ratio_area < 0.2:\n",
    "                threshold = \"Low\"\n",
    "            else:\n",
    "                threshold = \"Intermediate\"\n",
    "\n",
    "        # Update fields\n",
    "        row[2] = pc_value\n",
    "        row[3] = ratio_area\n",
    "        row[4] = threshold\n",
    "        cursor.updateRow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffa1d782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAD_1983_UTM_Zone_16N\n"
     ]
    }
   ],
   "source": [
    "print(arcpy.Describe(patches_hex).spatialReference.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e16b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, November 5, 2025 4:42:46 PM\",\"Succeeded at Wednesday, November 5, 2025 4:42:46 PM (Elapsed Time: 0.01 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This script merges hexagons classified as \"Biodiversity source\" and recalculates the area of the merged hexagons.\n",
    "\n",
    "# Set the name for the temporary shapefile to store the dissolved hexagons based on the classification\n",
    "\n",
    "hexagons_dissolved = os.path.join(dir,\"hexagons_dissolved.shp\") #temp\n",
    "\n",
    "# Dissolve by classification\n",
    "hexagons_dissolved = os.path.join(dir, \"hexagons_dissolved.shp\")\n",
    "arcpy.analysis.PairwiseDissolve(\n",
    "    in_features=hexagons_pc, \n",
    "    out_feature_class=hexagons_dissolved, \n",
    "    dissolve_field=\"Threshold\", \n",
    "    multi_part=\"SINGLE_PART\"\n",
    ")\n",
    "\n",
    "# Export only the Biodiversity source hexagons\n",
    "biodiversity_source = os.path.join(dir, \"biodiversity_source.shp\")\n",
    "arcpy.analysis.Select(\n",
    "    in_features=hexagons_dissolved,\n",
    "    out_feature_class=biodiversity_source,\n",
    "    where_clause=\"Threshold = 'Biodiversity source'\"\n",
    ")\n",
    "\n",
    "# Erase them from the full set\n",
    "hexagons_erased = os.path.join(dir, \"hexagons_erased.shp\")\n",
    "arcpy.analysis.Erase(\n",
    "    in_features=hexagons_pc,\n",
    "    erase_features=biodiversity_source,\n",
    "    out_feature_class=hexagons_erased\n",
    ")\n",
    "\n",
    "# Merge erased + biodiversity source back together\n",
    "hexagons_merged = os.path.join(dir, \"hexagons_merged.shp\")\n",
    "arcpy.management.Merge(\n",
    "    inputs=[hexagons_erased, biodiversity_source],\n",
    "    output=hexagons_merged,\n",
    "    field_mappings=None,\n",
    "    add_source=\"NO_SOURCE_INFO\"\n",
    ")\n",
    "\n",
    "# Select the hexagons that has no GRID_ID. This is the case of the hexagons dissolved that are classified as \"Biodiversity source\"\n",
    "hexagons_nulls = arcpy.management.SelectLayerByAttribute(\n",
    "    in_layer_or_view=hexagons_merged,\n",
    "    selection_type=\"NEW_SELECTION\",\n",
    "    where_clause=\"GRID_ID = ' '\",\n",
    "    invert_where_clause=None\n",
    ")\n",
    "\n",
    "# Set a new GRID_ID for the hexagons that has no GRID_ID\n",
    "arcpy.management.CalculateField(\n",
    "    in_table=hexagons_nulls,\n",
    "    field=\"GRID_ID\",\n",
    "    expression=\"'Z-' + str(!FID!)\",\n",
    "    expression_type=\"PYTHON3\",\n",
    "    code_block=\"\",\n",
    "    field_type=\"TEXT\",\n",
    "    enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    ")\n",
    "\n",
    "# Clear the selection\n",
    "arcpy.management.SelectLayerByAttribute(\n",
    "    in_layer_or_view=hexagons_nulls,\n",
    "    selection_type=\"CLEAR_SELECTION\"\n",
    ")\n",
    "\n",
    "# Get the spatial reference of the hexagons shapefile\n",
    "\n",
    "desc = arcpy.Describe(hexagons_nulls)\n",
    "SR = desc.spatialReference\n",
    "\n",
    "# Calculate the new area for final hexagons\n",
    "\n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "    in_features=hexagons_nulls,\n",
    "    geometry_property=\"Area_m2 AREA\",\n",
    "    length_unit=\"\",\n",
    "    area_unit=\"SQUARE_METERS\",\n",
    "    coordinate_system=SR,\n",
    "    coordinate_format=\"SAME_AS_INPUT\"\n",
    ")\n",
    "\n",
    "# Change the variable for the next steps\n",
    "hexagons_pc = os.path.join(dir,\"hexagons_pc_classified.shp\")\n",
    "\n",
    "# Create the final output shapefile\n",
    "# Use hexagons_merged as the input\n",
    "arcpy.management.CopyFeatures(hexagons_merged, hexagons_pc)\n",
    "\n",
    "#Erase temporal layers\n",
    "arcpy.management.Delete(hexagons_dissolved)\n",
    "arcpy.management.Delete(hexagons_erased)\n",
    "arcpy.management.Delete(hexagons_merged) # delete this temp file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4da602c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing hexagon Z-252 (#1) ===\n",
      "    Done in 268.73 seconds — PC=0.280669, ratio=0.864\n",
      "\n",
      "=== Processing hexagon Z-253 (#2) ===\n",
      "    Done in 13.11 seconds — PC=0.211757, ratio=0.613\n",
      "\n",
      "✅ Finished all hexagons in 4.70 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Re-calculate the PC index for each FL (hexagon) using the patches shapefile and the area field\n",
    "\n",
    "import time\n",
    "\n",
    "dir_patches2 = os.path.join(dir, \"PatchesHex2\")\n",
    "os.makedirs(dir_patches2, exist_ok=True)\n",
    "\n",
    "total_start = time.time()\n",
    "counter = 0\n",
    "\n",
    "with arcpy.da.UpdateCursor(hexagons_pc, [ID_field, area_hexagons, \"PC\", \"ratio\", \"Threshold\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        grid_id, area, pc_value, ratio_area, threshold = row\n",
    "        if threshold != \"Biodiversity source\":\n",
    "            continue  # only process relevant hexagons\n",
    "\n",
    "        counter += 1\n",
    "        print(f\"\\n=== Processing hexagon {grid_id} (#{counter}) ===\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        where_clause = f\"{ID_field} = '{grid_id}'\"\n",
    "        target_hex = arcpy.SelectLayerByAttribute_management(hexagons_pc, \"NEW_SELECTION\", where_clause)\n",
    "        patches_hex = os.path.join(dir_patches2, f\"{grid_id}.shp\")\n",
    "\n",
    "        # Clip patches to the current hexagon\n",
    "        arcpy.analysis.PairwiseClip(patches_layer, target_hex, patches_hex)\n",
    "\n",
    "        # If there are no patches in the hexagon, skip\n",
    "        count_result = arcpy.management.GetCount(patches_hex)\n",
    "        count = int(count_result.getOutput(0))\n",
    "        if count == 0:\n",
    "            pc_value = 0\n",
    "            ratio_area = 0\n",
    "            print(f\"    No patches found → PC = 0\")\n",
    "        else:\n",
    "            # Compute PC for the hexagon (fast version)\n",
    "            pc_value = PC_index(\n",
    "                patches=patches_hex,\n",
    "                area_field=area_patches,\n",
    "                total_area=area,\n",
    "                distance=distance,\n",
    "                pij=pij\n",
    "            )\n",
    "\n",
    "            # Compute area ratio\n",
    "            patches_area = 0\n",
    "            with arcpy.da.SearchCursor(patches_hex, [\"Area_m2\"]) as patches_cursor:\n",
    "                for patches_row in patches_cursor:\n",
    "                    patches_area += patches_row[0]\n",
    "            ratio_area = patches_area / area\n",
    "\n",
    "        # Update fields\n",
    "        row[2] = pc_value\n",
    "        row[3] = ratio_area\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"    Done in {elapsed:.2f} seconds — PC={pc_value:.6f}, ratio={ratio_area:.3f}\")\n",
    "\n",
    "total_elapsed = time.time() - total_start\n",
    "print(f\"\\n✅ Finished all hexagons in {total_elapsed/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7527541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priorization of restoration\n",
    "\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "# ─── PARAMETERS ───────────────────────────────────────────────────────────────\n",
    "\n",
    "pc_field    = \"PC\"\n",
    "class_field = \"Threshold\"\n",
    "\n",
    "# Define which class-values you want for connector analysis:\n",
    "INTERMEDIATE_CLASSES = [\"Intermediate\"]  # e.g. [\"MedRes\", \"IntRes\"]\n",
    "SOURCE_CLASSES       = [\"Biodiversity source\"]      # e.g. [\"Source\"]\n",
    "\n",
    "connector_classes = set(INTERMEDIATE_CLASSES + SOURCE_CLASSES)\n",
    "\n",
    "out_fields = [\"varPCflux\", \"varPCconn\", \"Priority\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e094967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make layer for spatial queries\n",
    "lyr = \"FL_lyr\"\n",
    "arcpy.MakeFeatureLayer_management(hexagons_pc, lyr)\n",
    "\n",
    "# 2. Build graph G of ALL FLs (nodes carry PC & Classification)\n",
    "G = nx.Graph()\n",
    "with arcpy.da.SearchCursor(lyr, [ID_field, pc_field, class_field]) as cur:\n",
    "    for oid, pc, cl in cur:\n",
    "        G.add_node(oid, PC=float(pc), Classification=cl)\n",
    "\n",
    "# 3. Add edges for immediate neighbors\n",
    "arcpy.MakeFeatureLayer_management(hexagons_pc, \"FL_main\")\n",
    "arcpy.MakeFeatureLayer_management(hexagons_pc, \"FL_compare\")\n",
    "\n",
    "\n",
    "for oid, in arcpy.da.SearchCursor(\"FL_main\", [ID_field]):\n",
    "    # select just that hexagon in the main layer\n",
    "    arcpy.SelectLayerByAttribute_management(\n",
    "        \"FL_main\", \"NEW_SELECTION\", f\"{ID_field} = '{oid}'\"\n",
    "    )\n",
    "    # find all hexagons in FL_compare that touch it\n",
    "    arcpy.SelectLayerByLocation_management(\n",
    "        \"FL_compare\", \"BOUNDARY_TOUCHES\", \"FL_main\",\n",
    "        \"\", \"NEW_SELECTION\"\n",
    "    )\n",
    "    # add edges for each neighbor found\n",
    "    with arcpy.da.SearchCursor(\"FL_compare\", [ID_field]) as nbr_cur:\n",
    "        for nbr_oid, in nbr_cur:\n",
    "            if nbr_oid != oid:\n",
    "                G.add_edge(oid, nbr_oid)\n",
    "    # clear selections before next iteration\n",
    "    arcpy.SelectLayerByAttribute_management(\"FL_main\", \"CLEAR_SELECTION\")\n",
    "    arcpy.SelectLayerByAttribute_management(\"FL_compare\", \"CLEAR_SELECTION\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ef20334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Calculate varPCflux\n",
    "# 4.1 Create a dictionary with the centroids of the hexagons and their PC values\n",
    "ids, pc_vals = [], []\n",
    "centroids = {}\n",
    "with arcpy.da.SearchCursor(hexagons_pc, [ID_field, \"PC\", \"SHAPE@XY\"]) as cur:\n",
    "    for oid, pc, xy in cur:\n",
    "        ids.append(oid)\n",
    "        pc_vals.append(pc)\n",
    "        centroids[oid] = xy\n",
    "\n",
    "n = len(ids)\n",
    "pc_array = np.array(pc_vals, dtype=float)\n",
    "# 4.2 Create a distance matrix\n",
    "dist_matrix = np.zeros((n, n), dtype=float)\n",
    "for i in range(n):\n",
    "    x1, y1 = centroids[ids[i]]\n",
    "    for j in range(n):\n",
    "        x2, y2 = centroids[ids[j]]\n",
    "        dist_matrix[i, j] = math.hypot(x1 - x2, y1 - y2)\n",
    "\n",
    "# 4.3 Decay constant k and p*ij matrix\n",
    "k = - math.log(pij) / distance # decay constant\n",
    "p_matrix = np.exp(-k * dist_matrix) # p*ij matrix\n",
    "\n",
    "# 4.4 Total flux (i≠j)\n",
    "flux_total = 0.0\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if i == j: \n",
    "            continue\n",
    "        flux_total += pc_array[i] * pc_array[j] * p_matrix[i, j]\n",
    "\n",
    "# 4.5 varPCflux for each hexagon\n",
    "var_flux = {}\n",
    "for idx, oid in enumerate(ids):\n",
    "    # máscara para excluir idx\n",
    "    mask = np.ones(n, dtype=bool)\n",
    "    mask[idx] = False\n",
    "    pc_mask = pc_array[mask]\n",
    "    p_mask = p_matrix[np.ix_(mask, mask)]\n",
    "\n",
    "    # flux without idx\n",
    "    flux_mask = 0.0\n",
    "    nm = n - 1\n",
    "    for i in range(nm):\n",
    "        for j in range(nm):\n",
    "            if i == j: \n",
    "                continue\n",
    "            flux_mask += pc_mask[i] * pc_mask[j] * p_mask[i, j]\n",
    "\n",
    "    var_flux[oid] = (flux_total - flux_mask) / flux_total if flux_total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d1e4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Normalize both to [0,1] and sum → Priority\n",
    "def normalize(d):\n",
    "    vals = list(d.values())\n",
    "    lo, hi = min(vals), max(vals)\n",
    "    if hi == lo:\n",
    "        return {k: 0.0 for k in d}\n",
    "    return {k: (v - lo) / (hi - lo) for k, v in d.items()}\n",
    "\n",
    "\n",
    "# 5.1 Create a dictionary with the PC values of all nodes\n",
    "# (this is needed for the varPCconnector calculation)\n",
    "all_pc = {n: G.nodes[n]['PC'] for n in G.nodes()}\n",
    "\n",
    "# --- 1) Define nodes “conector” ---\n",
    "connector_nodes = [\n",
    "    n for n,d in G.nodes(data=True)\n",
    "    if d[\"Classification\"] in connector_classes\n",
    "]\n",
    "\n",
    "# --- 2) Calculate PC_connector global ---\n",
    "# all_pc ya es {nodo: PC_nodo}\n",
    "# components of connector subgraph\n",
    "S = G.subgraph(connector_nodes)\n",
    "comps = list(nx.connected_components(S))\n",
    "\n",
    "PC_conn_total = 0.0\n",
    "for c1, c2 in combinations(comps, 2):\n",
    "    s1 = sum(all_pc[n] for n in c1)\n",
    "    s2 = sum(all_pc[n] for n in c2)\n",
    "    PC_conn_total += 2 * s1 * s2\n",
    "\n",
    "# --- 3) For each node, experiment with removing ---\n",
    "var_conn = {}\n",
    "for node in connector_nodes:\n",
    "    # Nodes without own node\n",
    "    nodes_minus = [n for n in connector_nodes if n != node]\n",
    "    S_minus = G.subgraph(nodes_minus)\n",
    "    comps_minus = list(nx.connected_components(S_minus))\n",
    "    \n",
    "    PC_conn_minus = 0.0\n",
    "    for c1, c2 in combinations(comps_minus, 2):\n",
    "        s1 = sum(all_pc[n] for n in c1)\n",
    "        s2 = sum(all_pc[n] for n in c2)\n",
    "        PC_conn_minus += 2 * s1 * s2\n",
    "\n",
    "    # Relative variation\n",
    "    var_conn[node] = (\n",
    "        (PC_conn_total - PC_conn_minus) / PC_conn_total\n",
    "        if PC_conn_total > 0 else 0.0\n",
    "    )\n",
    "\n",
    "\n",
    "# Normalize flux and connector values to [0,1]\n",
    "norm_flux = normalize(var_flux)\n",
    "norm_conn = normalize(var_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f82bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Function to calculate priority according to Tambosi 2014\n",
    "def calculate_priority_tambosi(n,norm_flux, norm_conn, classification):\n",
    "    \"\"\"Calcula prioridad según Tambosi 2014\"\"\"\n",
    "    if classification == \"Intermediate\":\n",
    "        return norm_flux[n] + norm_conn[n]\n",
    "    elif classification == \"Low\":\n",
    "        return 0.0\n",
    "    else:  # Biodiversity source\n",
    "        return 0.0\n",
    "\n",
    "# 6.1 Calculate priority for each node\n",
    "priority_tambosi = {\n",
    "    n: calculate_priority_tambosi(n, norm_flux, norm_conn, G.nodes[n]['Classification'])\n",
    "    for n in G.nodes\n",
    "}\n",
    "\n",
    "# 6.2 Normalize priority to [0,1]\n",
    "norm_priority = normalize(priority_tambosi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "166aa00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing results to hexagons shapefile.\n"
     ]
    }
   ],
   "source": [
    "# 7. Write results to hexagons shapefile\n",
    "existing = [f.name for f in arcpy.ListFields(hexagons_pc)]\n",
    "for fld in out_fields:\n",
    "    if fld not in existing:\n",
    "        arcpy.AddField_management(hexagons_pc, fld, \"DOUBLE\")\n",
    "\n",
    "with arcpy.da.UpdateCursor(hexagons_pc, [ID_field] + out_fields) as ucur:\n",
    "    for row in ucur:\n",
    "        oid = row[0]\n",
    "        row[1] = norm_flux.get(oid, 0.0)\n",
    "        row[2] = norm_conn.get(oid, 0.0)\n",
    "        row[3] = norm_priority.get(oid, 0.0)\n",
    "        ucur.updateRow(row)\n",
    "\n",
    "print(\"Finished writing results to hexagons shapefile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea5c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-py3-clone-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
